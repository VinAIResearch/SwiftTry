pretrained_base_model_path: "../pretrained_sd_models/stable-diffusion-inpainting"
pretrained_vae_path: "../pretrained_sd_models/sd-vae-ft-mse"
pretrained_referencenet_model_path: "../pretrained_sd_models/stable-diffusion-v1-5"
image_encoder_path: "../pretrained_sd_models/image_encoder"
denoising_unet_path: "./exp_output/stage2_vvt512_from_stage1_1024x768_ft_upblocks_aug(oot_mask)_flow_loss/checkpoint-100000/denoising_unet.pth"
reference_unet_path: "./exp_output/stage1_1024x768_ft_upblocks_aug/checkpoint-200000/reference_unet.pth"
pose_guider_path: "./exp_output/stage1_1024x768_ft_upblocks_aug/checkpoint-200000/pose_guider.pth"
motion_module_path: "./exp_output/stage2_vvt512_from_stage1_1024x768_ft_upblocks_aug(oot_mask)_flow_loss/motion_module-100000.pth"
flow_guider_path: "./exp_output/stage2_vvt512_from_stage1_1024x768_ft_upblocks_aug(oot_mask)_flow_loss/checkpoint-100000/flow_guider.pth"


inference_config: "./configs/inference/inference_v2.yaml"
weight_dtype: 'fp16'

width: 384
height: 512
filter_params:
  method: 'butterworth'
  n: 4
  d_s: 0.25
  d_t: 0.25
test_cases:
  "./configs/inference/ref_images/anyone-2.png":
    - "./configs/inference/pose_videos/anyone-video-2_kps.mp4" 
    - "./configs/inference/pose_videos/anyone-video-5_kps.mp4"
  "./configs/inference/ref_images/anyone-10.png":
    - "./configs/inference/pose_videos/anyone-video-1_kps.mp4"
    - "./configs/inference/pose_videos/anyone-video-2_kps.mp4"
  "./configs/inference/ref_images/anyone-11.png":
    - "./configs/inference/pose_videos/anyone-video-1_kps.mp4"
    - "./configs/inference/pose_videos/anyone-video-2_kps.mp4"
  "./configs/inference/ref_images/anyone-3.png":
    - "./configs/inference/pose_videos/anyone-video-2_kps.mp4"
    - "./configs/inference/pose_videos/anyone-video-5_kps.mp4"
  "./configs/inference/ref_images/anyone-5.png":
    - "./configs/inference/pose_videos/anyone-video-2_kps.mp4" 
